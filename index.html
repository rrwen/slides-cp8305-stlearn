<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8"/>

    <!-- Reveal Stylesheets -->
		<link rel="stylesheet" href="bower_components/reveal.js/css/reveal.css">
		<link rel="stylesheet" href="bower_components/reveal.js/css/theme/white.css">

    <!-- CSS Stylesheets -->
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="css/logos.css">
  </head>

	<body>

    <!-- Reveal Slides -->
		<div class="reveal">
			<div class="slides style">

        <section>
          <h1>Self-taught Learning: <br>Transfer Learning from Unlabeled Data</h1>
          <p>
            <br>Richard Wen
            <br>rwen@ryerson.ca
            <br>April 7, 2017
          </p>
          <p>
            <small><i>
              <br>Presented as an Article Summary for Course CP8305
              <br>Instructed by Dr. Cherie Ding
            </i></small>
          </p>
        </section>

        <section>
          <h2>Outline</h2>
          <p><ol>
            <li>Introduction</li>
            <li>Methods</li>
            <li>Results</li>
            <li>Discussion and Conclusion</li>
          </ol></p>
        </section>

				<section><h1>Introduction</h1></section>

				<section>
					<h2>Learning</h2>
          <img class="plain" src="img/learn_methods.png" width="80%">
        </section>

				<section>
          <h2>What We See</h2>
          <img class="plain" src="img/dog_cat.jpg" width="70%">
        </section>

				<section>
          <h2>What The Computer Sees</h2>
          <img class="plain" src="img/computer_sees.png" width="70%">
        </section>

				<section>
          <h2>Higher Level Features</h2>
          <img class="plain" src="img/dog_cat_edges.png" width="70%">
        </section>

				<section>
          <h2>Why?</h2>
					<p>
						<ul>
							<li>Labeled data is expensive</li>
							<li>Abundance of unlabeled data</li>
							<li>Less restrictive data requirements</li>
						</ul>
					</p>
        </section>

				<section><h1>Methods</h1></section>

				<section>
					<h2>Two Stages</h2>
					<p>
						<ol>
							<li>Learn representation with unlabeled data</li>
							<li>Apply to labeled data for classification</li>
						</ol>
					</p>
				</section>

				<section>
          <h2>Labeled Training Data</h2>
					<p>
						A set of <i>m</i> training examples with:
						<ul>
							<li><i>x</i> as <i>n</i>-dimension feature vectors</li>
							<li><i>y</i> as corresponding labels <i>{1 .. C}</i></li>
							<li><i>l</i> indicating a labeled example</li>
						</ul>
					</p>
					<!-- \left\{ ( x_l^{(1)}, y^{(1)} ) \dots\ (x_l^{(m)}, y^{(m)}) \right\} \in  \!R^n -->
					<img class="plain" src="img/eq_train_label.svg" width="80%">
					<small class="reference">Raina et al. (2007)</small>
        </section>

				<section>
          <h2>Unlabeled Training Data</h2>
					<p>
						A set of <i>k</i> training examples with:
						<ul>
							<li><i>x</i> as <i>n</i>-dimension feature vectors</li>
							<li><i>u</i> indicating an unlabeled example</li>
						</ul>
					</p>
					<!-- \left\{  x_u^{(1)} \dots\ x_u^{(k)} \right\} \in  \!R^n -->
					<img class="plain" src="img/eq_train_unlabel.svg" width="50%">
					<small class="reference">Raina et al. (2007)</small>
        </section>

				<section>
					<h2>Learning Bases (Basic Elements)</h2>
					<p>
						Optimize <i>aj</i> weights and <i>bj</i> bases to:
						<ol>
							<li>Reconstruct <i>xu</i> as weighted linear combo of bases</li>
							<li>Encourage <i>aj</i> to be sparse (mostly zero)</li>
						</ol>
					</p>
					<!-- minimize_{b,a} \sum \left \| x_u^{(i)} - \sum_j a_j^{(i)}b_j \right \|_2^2 + \beta \left \| a^{(i)} \right \|_1 \\ \textrm{such that} \left \| b_j \right \|_2 \leq 1, \forall j \in 1, \dots s  -->
					<img class="plain" src="img/eq_bases.svg" width="80%">
					<small class="reference">Raina et al. (2007)</small>
				</section>

				<section>
					<h2>Learning Features</h2>
					<p>
						Using <i>bj</i>, compute sparse features from labeled data as input to supervised algorithms
					</p>
					<!-- \hat a (x_l^{(i)})) = argmin_a \left \| x_l^{(i)} - \sum_j a_j^{(i)}b_j \right \|_2^2 + \beta \left \| a^{(i)} \right \|_1 -->
					<img class="plain" src="img/eq_features.svg" width="80%">
					<small class="reference">Raina et al. (2007)</small>
				</section>

				<section>
					<h2>Sparse Features Example</h2>
					<img class="plain" src="img/ex_features.png" width="80%">
					<small class="reference">Raina et al. (2007)</small>
				</section>

				<section><h1>Results</h1></section>

				<section>
					<h2>Classification Experiments</h2>
					<p>
						<ul>
							<li>Principal Component Analysis (PCA) vs Raw vs Sparse Coding (SC) Features</li>
							<li>Support Vector Machine (SVM)</li>
							<li>Gaussian Discriminant Analysis (GDA)</li>
						</ul>
					</p>
				</section>

				<section data-background-image="img/digits.png">
					<h2>Handwritten Digits and English Characters</h2>
					<p>
						<ul>
							<li>Improvements when SC used with Raw for characters</li>
							<li>SC did not perform as well alone for characters</li>
							<li>SC generally performed better for digits</li>
							<li>Improvements ranged from ~1-7%</li>
						</ul>
					</p>
				</section>

				<section data-background-image="img/news.jpg">
					<h2>Reuters Webpages and Articles</h2>
					<p>
						<ul>
							<li>SC generally performed well for webpages and articles</li>
							<li>Improvements ranged from ~8-21%</li>
						</ul>
					</p>
				</section>

				<section data-background-image="img/kernel.png">
					<h2>Kernels (Similarity Functions)</h2>
					<p>
						<ul>
							<li>Compared against linear, polynomials, Radial Basis Function (RBF)</li>
							<li>Outperforms standard kernel choices above</li>
							<li>Improvements ranged from ~6-13%</li>
						</ul>
					</p>
				</section>

				<section><h1>Discussion and Conclusion</h1></section>

				<section>
					<h2>Discussion</h2>
					<p>
						<ul>
							<li>Can be applied to different domains</li>
							<li>Can have more basis vectors <i>bj</i> than n-dimensions</li>
							<li>Unlabeled data must still have some structure</li>
							<li>Other algorithms can be modified for self-taught learning</li>
						</ul>
					</p>
				</section>

				<section>
					<h2>Conclusion</h2>
					<p>
						<ul>
							<li>Find higher level representations of patterns</li>
							<li>Use of inexpensive unlabeled data</li>
							<li>Self-taught learning as a machine learning framework</li>
						</ul>
					</p>
				</section>

				<section>
          <h2>References</h2>
          <small><ul>
            <li>Raina, R., Battle, A., Lee, H., Packer, B., & Ng, A. Y. (2007). Self-taught learning. Proceedings of the 24th international conference on Machine learning - ICML '07. doi:10.1145/1273496.1273592</li>
          </ul></small>
        </section>

			</div>
		</div>

    <!-- Logos -->
    <div class = "logo">
      <a href="http://www.ryerson.ca/"><img src="img/ryerson_logo.png" class="logo"></a>
    </div>

    <!-- Reveal JavaScript -->
		<script type="text/javascript" src="bower_components/reveal.js/js/reveal.js"></script>
		<script>
		  Reveal.initialize({});
      Reveal.configure({slideNumber: true});
    </script>

  </body>
</html>
